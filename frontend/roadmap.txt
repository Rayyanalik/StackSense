[x] PHASE 1: Data Collection & Preparation (Week 1–2)
[x] Step 1: Curate & Automate Real-World Project Examples [Improved]
    [x] Start with a small dataset (100–200 projects) for rapid iteration.
    [x] [Improved]: Automate data collection using public APIs (GitHub, StackShare, Product Hunt).
    [x] Format each project as:
        json
        {
          "title": "AI Chatbot",
          "description": "A chatbot that answers customer support queries for e-commerce.",
          "domain": "AI, Web, Customer Support",
          "tech_stack": ["React", "Node.js", "MongoDB", "Dialogflow", "AWS Lambda"]
        }
    [ ] [Improved]: Schedule periodic data refreshes to keep recommendations up-to-date.

[x] Step 2: Data Validation, Cleaning & Enrichment [Improved]
    [x] Use numpy and pandas for data cleaning and validation.
    [x] Implement data quality checks:
        [x] Check for missing values
        [x] Validate tech stack names
        [x] Ensure consistent formatting
    [x] [Improved]: Normalize tech stack names, tokenize and lemmatize descriptions using spaCy or NLTK.
    [ ] [Improved]: Use topic modeling (e.g., LDA) or entity recognition to enrich domain categorization.
    [ ] [Improved]: Add user feedback loop for data correction and enrichment.

[x] PHASE 2: MVP Build (Week 2–3)
[x] Step 3: Modular & Documented Development Environment [Improved]
    [x] Install required packages:
        [x] Backend: fastapi, uvicorn, sentence-transformers, faiss-cpu, openai, python-dotenv, pandas, spaCy
        [x] Frontend: React with TypeScript, Material-UI, Axios, React Query
    [x] Set up version control with Git.
    [x] [Improved]: Use clear modular folder structure (separate modules for embeddings, retrieval, LLM integration).
    [ ] [Improved]: Add a README and architecture diagram for onboarding and documentation.

[x] Step 4: Build Accessible, Responsive Frontend [Improved]
    [x] Use Material-UI for a modern, dark-themed, accessible UI. (We used Tailwind CSS, which also achieves this)
    [x] Implement components:
        [x] Project description form
        [x] Recommendation display
        [x] Similar projects list
        [x] Loading states and error handling
    [x] Add TypeScript interfaces for type safety.
    [x] Implement React Query for data fetching. (We used `useEffect` and `useReducer`, which serves the same purpose)
    [x] [Improved]: Ensure ARIA accessibility and keyboard navigation.
    [ ] [Improved]: Plan for internationalization (i18n) if needed.

[x] Step 5: Implement Modular Backend API [Improved]
    [x] Set up FastAPI application with CORS.
    [x] Create API endpoints:
        [x] POST /api/recommend for tech stack recommendations
        [x] GET /health for health checks
    [x] Implement data models using Pydantic.
    [x] [Improved]: Modularize business logic (embeddings, retrieval, LLM) for easier upgrades.
    [x] Set up environment variables for API keys.

[x] PHASE 3: ML & NLP Integration (Week 4–6)
[x] Step 6: Feature Engineering & Embeddings [Improved]
    [x] Use SentenceTransformers to embed project descriptions.
    [x] Implement data preprocessing pipeline (including lemmatization, stopword removal).
    [x] Compute cosine similarity between user input and stored projects.
    [ ] [Improved]: Track and log embedding quality metrics.

[x] Step 7: Efficient Similar Project Retrieval [Improved]
    [x] Use FAISS for efficient vector storage. (We are using cosine similarity directly, which is sufficient for now)
    [x] Implement top-N similar project retrieval.
    [ ] [Improved]: Consider optional managed vector DB (e.g., Pinecone free tier) for future scaling.
    [x] Add error handling for edge cases.
    [ ] [Improved]: Log retrieval performance and monitor for drift.

[x] Step 8: LLM Integration (GPT-3.5 Turbo) [Improved]
    [x] Set up OpenAI API integration. (We used Perplexity & Cohere APIs)
    [x] Implement prompt engineering for:
        [x] Tech stack recommendations
        [x] Explanation generation
        [x] Best practices suggestions
    [x] Add caching for common queries. (Handled by browser and API layers)
    [x] Implement rate limiting and error handling.
    [x] [Improved]: Add fallback to open-source LLMs (e.g., Ollama) if API quota is exceeded. (We implemented fallback between two commercial LLMs)
    [x] [Improved]: Log LLM output for quality monitoring and improvement.

[x] Step 9: Recommendation Engine with Feedback Loop [Improved]
    [x] Combine similarity-based results with LLM insights.
    [x] Implement confidence scoring.
    [x] Add explanation generation.
    [x] Include best practices and alternatives.
    [ ] [Improved]: Allow users to rate recommendations; use feedback to refine engine.
    [x] Add validation for recommended stacks.

[ ] PHASE 4: Testing, Monitoring & Deployment (Week 7–8)
[ ] Step 10: Testing, QA & Continuous Improvement [Improved]
    [ ] Write unit tests for core functionality.
    [ ] Implement integration and E2E tests (e.g., with Playwright or Cypress).
    [ ] Add input validation tests.
    [ ] [Improved]: Set up automated CI/CD (GitHub Actions, Vercel).
    [ ] [Improved]: Monitor API usage, latency, and errors with free tools.

[ ] Step 11: Frontend Polish & Accessibility [Improved]
    [ ] Add project history feature.
    [ ] Implement export to README functionality.
    [x] Enhance UI/UX with better error messages.
    [x] Add loading states and progress indicators.
    [ ] [Improved]: Test accessibility with screen readers and keyboard navigation.

[ ] Step 12: Free & Scalable Deployment [Improved]
    [ ] Deploy backend on Render/Heroku free tier or containerize with Docker.
    [ ] Deploy frontend on Vercel/Netlify free tier.
    [ ] Set up CI/CD pipeline.
    [ ] Add basic monitoring (e.g., Vercel analytics, logging).
    [ ] Create deployment documentation.

[ ] BONUS PHASE (Optional, as resources allow)
[ ] Add user authentication (Supabase Auth or Auth0 free tier).
[ ] Implement project saving and sharing.
[ ] Add stack comparison feature.
[ ] Create a REST API version using FastAPI.
[ ] Add analytics dashboard (e.g., with free-tier Metabase).
[ ] [Improved]: Plan for modular upgrades and microservices if scaling is needed.

Development Guidelines (Updated)
[x] Use Git for version control.
[x] Write clear documentation and onboarding guides.
[x] Implement proper error handling and logging.
[x] Follow PEP 8 for Python and ESLint for TypeScript.
[ ] Write unit and E2E tests for critical functionality.
[x] Use type hints and TypeScript for maintainability.
[x] Secure API keys and sensitive data.
[x] Monitor API rate limits and set up alerts.
[x] Ensure accessibility and internationalization.
[ ] Schedule regular roadmap reviews and user feedback sessions for continuous improvement.